{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T10:13:48.187824Z","iopub.execute_input":"2025-12-19T10:13:48.188153Z","iopub.status.idle":"2025-12-19T10:13:48.194719Z","shell.execute_reply.started":"2025-12-19T10:13:48.188130Z","shell.execute_reply":"2025-12-19T10:13:48.193507Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\n**Welcome to the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you built a **single agent** that could take action. Now, you'll learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\n## ‚ÄºÔ∏è Please Read\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:10:41.998289Z","iopub.execute_input":"2025-12-19T11:10:41.998615Z","iopub.status.idle":"2025-12-19T11:10:42.104526Z","shell.execute_reply.started":"2025-12-19T11:10:41.998595Z","shell.execute_reply":"2025-12-19T11:10:42.103143Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"### 1.3: Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:10:47.835160Z","iopub.execute_input":"2025-12-19T11:10:47.835817Z","iopub.status.idle":"2025-12-19T11:10:47.843979Z","shell.execute_reply.started":"2025-12-19T11:10:47.835782Z","shell.execute_reply":"2025-12-19T11:10:47.842157Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"### 1.4: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"retry_config=types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:10:50.057070Z","iopub.execute_input":"2025-12-19T11:10:50.057597Z","iopub.status.idle":"2025-12-19T11:10:50.064879Z","shell.execute_reply.started":"2025-12-19T11:10:50.057558Z","shell.execute_reply":"2025-12-19T11:10:50.063216Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"---\n## ü§î Section 2: Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:10:58.589529Z","iopub.execute_input":"2025-12-19T11:10:58.589875Z","iopub.status.idle":"2025-12-19T11:10:58.597653Z","shell.execute_reply.started":"2025-12-19T11:10:58.589849Z","shell.execute_reply":"2025-12-19T11:10:58.596227Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:10:59.915101Z","iopub.execute_input":"2025-12-19T11:10:59.915549Z","iopub.status.idle":"2025-12-19T11:10:59.923063Z","shell.execute_reply.started":"2025-12-19T11:10:59.915521Z","shell.execute_reply":"2025-12-19T11:10:59.921731Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:11:01.216987Z","iopub.execute_input":"2025-12-19T11:11:01.217321Z","iopub.status.idle":"2025-12-19T11:11:01.224328Z","shell.execute_reply.started":"2025-12-19T11:11:01.217300Z","shell.execute_reply":"2025-12-19T11:11:01.223283Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail on Day 2.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"What are the latest advancements in quantum computing and what do they mean for AI?\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:11:02.610211Z","iopub.execute_input":"2025-12-19T11:11:02.610757Z","iopub.status.idle":"2025-12-19T11:11:12.510032Z","shell.execute_reply.started":"2025-12-19T11:11:02.610726Z","shell.execute_reply":"2025-12-19T11:11:12.508397Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in quantum computing and what do they mean for AI?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > Quantum computing is rapidly advancing and is set to revolutionize artificial intelligence. These advancements offer enhanced computational power and speed, enabling AI to train models and solve complex problems much faster than before. Quantum algorithms are particularly adept at optimization and pattern recognition, which will improve AI applications in machine learning, data analysis, and intricate problem-solving.\n\nKey developments include more stable qubits through error correction techniques and the creation of quantum software and algorithms to make the technology more accessible. As a result, quantum computing will empower AI to address challenges previously considered intractable, such as those in drug discovery and materials science. This fusion of quantum computing and AI, often called Quantum AI, promises significant breakthroughs across diverse fields like healthcare, finance, and logistics, heralding a transformative era for technological advancement.\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## üö• Section 3: Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:11:20.407389Z","iopub.execute_input":"2025-12-19T11:11:20.408737Z","iopub.status.idle":"2025-12-19T11:11:20.416344Z","shell.execute_reply.started":"2025-12-19T11:11:20.408692Z","shell.execute_reply":"2025-12-19T11:11:20.414919Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\",  # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:11:22.352326Z","iopub.execute_input":"2025-12-19T11:11:22.352688Z","iopub.status.idle":"2025-12-19T11:11:22.360722Z","shell.execute_reply.started":"2025-12-19T11:11:22.352662Z","shell.execute_reply":"2025-12-19T11:11:22.359097Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\",  # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:11:23.909114Z","iopub.execute_input":"2025-12-19T11:11:23.909479Z","iopub.status.idle":"2025-12-19T11:11:23.917163Z","shell.execute_reply.started":"2025-12-19T11:11:23.909455Z","shell.execute_reply":"2025-12-19T11:11:23.916010Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:11:26.074526Z","iopub.execute_input":"2025-12-19T11:11:26.076177Z","iopub.status.idle":"2025-12-19T11:11:26.083847Z","shell.execute_reply.started":"2025-12-19T11:11:26.076134Z","shell.execute_reply":"2025-12-19T11:11:26.082031Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a blog post about the benefits of multi-agent systems for software developers\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:11:27.703231Z","iopub.execute_input":"2025-12-19T11:11:27.704037Z","iopub.status.idle":"2025-12-19T11:11:40.152919Z","shell.execute_reply.started":"2025-12-19T11:11:27.704005Z","shell.execute_reply":"2025-12-19T11:11:40.151873Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > Okay, I am OutlineAgent. Here is a blog outline about the benefits of multi-agent systems for software developers:\n\n## Blog Outline:\n\n**Headline:** Unlock Superpowers for Your Code: How Multi-Agent Systems Revolutionize Software Development\n\n**Introduction Hook:** Ever feel like your software projects are struggling under the weight of complexity, struggling to keep up with dynamic environments, or simply not performing as efficiently as they could? What if there was a way to break down these challenges, foster intelligent collaboration within your applications, and build more robust, adaptable, and powerful software? Enter Multi-Agent Systems (MAS), a paradigm shift that's no longer just for researchers ‚Äì it's a powerful toolkit for the modern software developer.\n\n---\n\n### **Main Section 1: Tackling Complexity with Distributed Intelligence**\n\n*   **Decomposition and Modularity:** MAS allows you to break down large, monolithic applications into smaller, independent, and more manageable \"agents.\" Each agent can be responsible for a specific task or domain, making code easier to understand, develop, and maintain.\n*   **Emergent Behavior:** Instead of explicitly programming every interaction, agents in a MAS can interact with each other based on their individual goals and perceptions. This can lead to complex, intelligent, and often unexpected \"emergent\" behaviors that solve problems in novel ways.\n*   **Improved Scalability:** By distributing tasks and intelligence across multiple agents, MAS naturally lends itself to scalable solutions. You can add more agents to handle increased load or complexity without fundamentally redesigning the entire system.\n\n### **Main Section 2: Enhancing Adaptability and Resilience**\n\n*   **Dynamic Environments:** In real-world applications, environments change constantly. MAS excels here because individual agents can adapt their behavior based on local information, allowing the overall system to respond gracefully to unforeseen circumstances.\n*   **Fault Tolerance:** If one agent fails, the system doesn't necessarily collapse. Other agents can potentially take over its responsibilities or compensate for its absence, leading to more resilient and fault-tolerant software.\n*   **Self-Organization and Learning:** Agents can be designed to learn from their experiences and adapt their strategies over time. This can lead to systems that improve their performance autonomously and self-organize to optimize their operations.\n\n### **Main Section 3: Accelerating Development and Innovation**\n\n*   **Specialized Agent Libraries:** As MAS gains traction, expect to see a proliferation of pre-built, specialized agent libraries and frameworks. This allows developers to leverage existing solutions for common tasks, speeding up development cycles.\n*   **Parallel Development:** Different teams or developers can work on individual agents concurrently, as long as they adhere to defined communication protocols. This parallelization can significantly shorten development timelines.\n*   **Experimentation and Prototyping:** MAS provides a flexible platform for experimenting with different system designs and behaviors. It's easier to prototype and test new ideas by modifying or adding agents, fostering a culture of innovation.\n\n---\n\n**Concluding Thought:** Multi-Agent Systems offer a powerful new lens through which software developers can approach problem-solving. By embracing distributed intelligence, inherent adaptability, and accelerated development, you can build software that is not only more robust and efficient but also more intelligent and capable of navigating the ever-evolving digital landscape. Are you ready to give your code superpowers?\nWriterAgent > ## Unlock Superpowers for Your Code: How Multi-Agent Systems Revolutionize Software Development\n\nEver feel like your software projects are wrestling with overwhelming complexity, struggling to keep pace with a dynamic world, or just not performing at their peak? What if you could break down these challenges, foster intelligent collaboration within your applications, and build software that's more robust, adaptable, and powerful? It's time to discover Multi-Agent Systems (MAS), a paradigm shift that's no longer confined to research labs ‚Äì it's a potent toolkit for today's software developers.\n\nAt its core, MAS tackles complexity by embracing distributed intelligence. Imagine breaking down a monolithic application into smaller, independent \"agents,\" each handling a specific task. This decomposition makes your codebase far more understandable, manageable, and maintainable. What‚Äôs truly exciting is the potential for emergent behavior; instead of explicitly coding every interaction, agents collaborate based on their individual goals and perceptions, leading to intelligent solutions that can surprise and delight. This distributed nature also inherently boosts scalability. Need more power? Simply add more agents.\n\nBeyond complexity, MAS enhances adaptability and resilience. In our ever-changing digital environments, agents can independently adjust their behavior based on local information, allowing the entire system to respond gracefully to unexpected shifts. This distributed intelligence also offers impressive fault tolerance. If one agent stumbles, the system can often continue functioning, with other agents potentially taking over or compensating. Plus, agents can be designed to learn and self-organize, leading to systems that autonomously improve and optimize.\n\nFinally, MAS accelerates the development process itself. As the field matures, expect a surge of specialized agent libraries and frameworks, allowing you to leverage pre-built solutions. The ability for different teams to work on individual agents concurrently, as long as they follow defined communication protocols, can drastically shorten development timelines. MAS also provides a flexible sandbox for experimentation and prototyping. It's easier than ever to test new ideas by simply tweaking or adding agents, fostering a culture of innovation.\n\nMulti-Agent Systems offer a revolutionary way to approach software development. By embracing distributed intelligence, inherent adaptability, and accelerated innovation, you can build software that's not just efficient, but truly intelligent and ready for the future. Isn't it time to give your code superpowers?\nEditorAgent > ## Unlock Superpowers for Your Code: How Multi-Agent Systems Revolutionize Software Development\n\nDo your software projects often feel bogged down by overwhelming complexity, struggle to adapt to a rapidly changing digital landscape, or simply fall short of their peak performance? Imagine a way to dismantle these challenges, cultivate intelligent collaboration within your applications, and engineer software that is significantly more robust, adaptable, and powerful. This is the promise of Multi-Agent Systems (MAS)‚Äîa transformative paradigm that has moved beyond the research lab to become an indispensable toolkit for today's software developers.\n\nAt its heart, MAS addresses complexity by leveraging distributed intelligence. Picture breaking down a large, monolithic application into numerous smaller, independent \"agents,\" each meticulously designed to handle a specific task. This modular approach makes your codebase vastly more comprehensible, manageable, and maintainable. The true magic lies in the potential for emergent behavior: instead of explicitly scripting every single interaction, agents collaborate dynamically based on their unique goals and perceptions. This leads to intelligent solutions that can achieve outcomes exceeding initial expectations. Furthermore, this distributed architecture inherently bolsters scalability. Need to enhance system capacity? Simply introduce more agents.\n\nBeyond simplifying complexity, MAS dramatically improves adaptability and resilience. In today's perpetually evolving digital environments, agents can independently modify their behavior in response to localized information. This allows the entire system to react smoothly and effectively to unexpected shifts. This distributed intelligence also translates into impressive fault tolerance. Should one agent encounter an issue, the system can often continue operating seamlessly, with other agents potentially assuming its duties or compensating for its absence. Moreover, agents can be engineered to learn and self-organize, paving the way for systems that autonomously refine and optimize their operations over time.\n\nFinally, MAS offers a significant advantage in accelerating the development process itself. As the field matures, we can anticipate an influx of specialized agent libraries and frameworks, enabling developers to readily integrate pre-built solutions. The capacity for different teams to work on individual agents concurrently‚Äîprovided they adhere to established communication protocols‚Äîcan drastically reduce development timelines. MAS also provides a flexible environment for experimentation and rapid prototyping. Testing new concepts becomes considerably easier by simply modifying or adding agents, fostering a vibrant culture of innovation.\n\nMulti-Agent Systems present a revolutionary approach to software development. By embracing distributed intelligence, inherent adaptability, and accelerated innovation, you can construct software that is not only efficient but genuinely intelligent and future-ready. Isn't it time to imbue your code with extraordinary capabilities?\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n## üõ£Ô∏è Section 4: Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:11:50.146948Z","iopub.execute_input":"2025-12-19T11:11:50.147256Z","iopub.status.idle":"2025-12-19T11:11:50.154655Z","shell.execute_reply.started":"2025-12-19T11:11:50.147236Z","shell.execute_reply":"2025-12-19T11:11:50.153126Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:11:50.691012Z","iopub.execute_input":"2025-12-19T11:11:50.692165Z","iopub.status.idle":"2025-12-19T11:11:50.699170Z","shell.execute_reply.started":"2025-12-19T11:11:50.692129Z","shell.execute_reply":"2025-12-19T11:11:50.698021Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:11:52.052553Z","iopub.execute_input":"2025-12-19T11:11:52.052938Z","iopub.status.idle":"2025-12-19T11:11:52.059886Z","shell.execute_reply.started":"2025-12-19T11:11:52.052913Z","shell.execute_reply":"2025-12-19T11:11:52.058576Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:11:53.739610Z","iopub.execute_input":"2025-12-19T11:11:53.740103Z","iopub.status.idle":"2025-12-19T11:11:53.748055Z","shell.execute_reply.started":"2025-12-19T11:11:53.740074Z","shell.execute_reply":"2025-12-19T11:11:53.746902Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":45},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:11:57.029882Z","iopub.execute_input":"2025-12-19T11:11:57.030245Z","iopub.status.idle":"2025-12-19T11:11:57.037455Z","shell.execute_reply.started":"2025-12-19T11:11:57.030223Z","shell.execute_reply":"2025-12-19T11:11:57.036153Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Run the daily executive briefing on Tech, Health, and Finance\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:11:58.722109Z","iopub.execute_input":"2025-12-19T11:11:58.722499Z","iopub.status.idle":"2025-12-19T11:13:07.745120Z","shell.execute_reply.started":"2025-12-19T11:11:58.722474Z","shell.execute_reply":"2025-12-19T11:13:07.743865Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nHealthResearcher > Here's a concise briefing on recent breakthroughs:\n\n**Health:**\n*   **Custom Gene Therapy for Rare Disorders:** Personalized gene therapies, like base editing, are now correcting mutations in infants with rare genetic diseases, offering a chance for normal development. This approach is expected to expand to more conditions in the next 1-3 years.\n*   **AI-Enhanced Diagnostics:** Artificial intelligence is improving the accuracy of medical imaging for conditions like heart disease and cancer, promising earlier detection and better treatment outcomes. Widespread integration into clinical practice is anticipated within 2-5 years.\n\n**Technology:**\n*   **Edge AI and 5G Expansion:** Devices are increasingly processing AI locally, enhancing speed, privacy, and efficiency, amplified by 5G networks. This trend is already impactful and will continue to grow, with significant advancements expected in the next 1-3 years.\n\n**Finance:**\n*   **Stablecoin Settlement:** Visa has launched stablecoin settlement in the U.S., enabling faster, 7-day transactions for financial institutions and modernizing treasury operations. This integration is expected to broaden across the financial sector in the next 1-3 years.\nTechResearcher > **AI/ML Trends: Key Developments, Companies, and Impact**\n\nThe field of Artificial Intelligence (AI) and Machine Learning (ML) is rapidly evolving, with several key developments poised to reshape industries.\n\n**Key Developments:**\n\n1.  **Generative AI and Multimodal Models:** Generative AI continues its impressive trajectory, moving beyond text to create sophisticated images, video, and audio. Multimodal AI, which integrates various data types like text, images, and audio, is enhancing natural language understanding and creating more human-like interactions.\n2.  **Agentic AI and Automation:** AI agents are becoming more sophisticated, capable of autonomously managing complex workflows and tasks with minimal human intervention. This trend is driving significant advancements in automation across various business functions.\n3.  **Smaller, More Efficient Models (SLMs):** There's a growing shift towards smaller, specialized language models (SLMs) and more efficient AI architectures. These models are less resource-intensive, making AI more accessible and deployable on edge devices, while still offering competitive performance for specific tasks.\n\n**Main Companies Involved:**\n\n*   **Tech Giants:** Google (Vertex AI, Gemini), Microsoft (Azure AI), Amazon (AWS), NVIDIA (GPUs, AI infrastructure), and Meta are at the forefront, developing foundational models and AI platforms.\n*   **Cloud Providers & Platform Developers:** Companies like Databricks and Dataiku are crucial for providing the data intelligence platforms and low-code/no-code solutions that democratize AI development.\n*   **Specialized AI Companies:** Adobe (Adobe Firefly for creative content) and many others are integrating AI into their specific product offerings.\n\n**Potential Impact:**\n\nThese AI/ML trends are driving significant business transformation by boosting productivity, enabling cost reductions through automation, enhancing customer experiences with personalization, and accelerating innovation. The global AI market is projected for substantial growth, indicating a profound and lasting impact across all sectors of the economy. Ethical considerations and AI governance are also becoming increasingly important as AI integration deepens.\nFinanceResearcher > **Fintech Trends: Key Insights for 2025 and Beyond**\n\n**1. Embedded Finance:** This trend integrates financial services directly into non-financial platforms, creating seamless customer experiences. Market implications include increased customer loyalty and new revenue streams for businesses, while financial institutions gain broader distribution channels. The future outlook is robust, with projections indicating substantial market growth, driven by e-commerce and demand for convenience.\n\n**2. Artificial Intelligence (AI) and Machine Learning (ML):** AI and ML are increasingly embedded across financial services for tasks like fraud detection, personalized advice, and risk assessment. Market implications involve enhanced operational efficiency and improved customer engagement. The future sees AI agents handling more complex workflows and a hybrid model of AI and human oversight for strategic decision-making.\n\n**3. Open Banking:** Open banking facilitates secure sharing of financial data via APIs, fostering competition and innovation. Market implications include greater consumer control over data, streamlined processes, and new service offerings from fintechs. The future outlook points towards \"Open Finance,\" expanding beyond payments to encompass broader financial services, driving financial inclusion and more personalized experiences.\nAggregatorAgent > ## Executive Summary: Converging Trends in AI, Health, and Finance\n\n**Key Takeaways:** Artificial Intelligence (AI) and Machine Learning (ML) are no longer nascent technologies but foundational drivers across all sectors, significantly impacting healthcare and finance. A notable common thread is the increasing sophistication and accessibility of AI, from generative and agentic models to smaller, efficient versions, enabling broader applications.\n\n**Surprising Connections:** AI's role in healthcare is rapidly advancing, with AI-enhanced diagnostics promising earlier disease detection and personalized gene therapies offering novel treatments for rare disorders. Simultaneously, AI is revolutionizing finance through embedded services, fraud detection, and personalized advice, with emerging trends like stablecoin settlement and open banking further modernizing financial operations. The expansion of Edge AI, amplified by 5G, will further accelerate these developments by enabling localized, efficient processing.\n\n**Most Important Insights:** The pervasive influence of AI signifies a future of increased automation, enhanced personalization, and profound business transformation. Businesses must leverage these converging trends to boost productivity, reduce costs, and innovate. As AI integration deepens, ethical considerations and robust governance will be paramount to harnessing its full potential responsibly.\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n## ‚û∞ Section 5: Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\",  # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:13:20.162349Z","iopub.execute_input":"2025-12-19T11:13:20.162690Z","iopub.status.idle":"2025-12-19T11:13:20.169713Z","shell.execute_reply.started":"2025-12-19T11:13:20.162666Z","shell.execute_reply":"2025-12-19T11:13:20.168235Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\",  # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:13:21.990254Z","iopub.execute_input":"2025-12-19T11:13:21.991621Z","iopub.status.idle":"2025-12-19T11:13:22.000810Z","shell.execute_reply.started":"2025-12-19T11:13:21.991509Z","shell.execute_reply":"2025-12-19T11:13:21.998544Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:13:25.396147Z","iopub.execute_input":"2025-12-19T11:13:25.396509Z","iopub.status.idle":"2025-12-19T11:13:25.403464Z","shell.execute_reply.started":"2025-12-19T11:13:25.396476Z","shell.execute_reply":"2025-12-19T11:13:25.402505Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    output_key=\"current_story\",  # It overwrites the story with the new, refined version.\n    tools=[\n        FunctionTool(exit_loop)\n    ],  # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:13:27.859328Z","iopub.execute_input":"2025-12-19T11:13:27.859754Z","iopub.status.idle":"2025-12-19T11:13:27.869053Z","shell.execute_reply.started":"2025-12-19T11:13:27.859726Z","shell.execute_reply":"2025-12-19T11:13:27.867716Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":51},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2,  # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:13:30.352063Z","iopub.execute_input":"2025-12-19T11:13:30.352476Z","iopub.status.idle":"2025-12-19T11:13:30.361500Z","shell.execute_reply.started":"2025-12-19T11:13:30.352445Z","shell.execute_reply":"2025-12-19T11:13:30.359996Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map in 50 words\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T11:13:32.429378Z","iopub.execute_input":"2025-12-19T11:13:32.429773Z","iopub.status.idle":"2025-12-19T11:13:41.510499Z","shell.execute_reply.started":"2025-12-19T11:13:32.429746Z","shell.execute_reply":"2025-12-19T11:13:41.509300Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map in 50 words\nInitialWriterAgent > Elias polished the great lens, the beam cutting through the fog. A glint caught his eye ‚Äì a rolled parchment tucked into a crevice. Unfurling it revealed not paper, but something akin to hardened moonlight. Strange symbols pulsed with an internal, sapphire glow, charting an ocean no sailor knew.\nCriticAgent > The story is intriguing and sets up a compelling mystery. However, it could benefit from a little more depth.\n\nHere are a few suggestions:\n\n1.  **Elaborate on Elias's reaction:** What are his immediate thoughts or feelings upon finding and examining this unusual map? Is he awestruck, fearful, curious, or a mix of emotions? Showing his internal response would make him a more relatable character.\n2.  **Hint at the map's purpose or origin:** While the mystery is part of the charm, a subtle hint about what this \"ocean no sailor knew\" might contain, or where the map could have come from, could deepen the reader's engagement. For example, does Elias recognize any of the symbols, or does the map seem to react to his touch?\n3.  **Consider a slight expansion of the description:** The description of the \"hardened moonlight\" and \"sapphire glow\" is evocative, but perhaps a sentence or two more could flesh out the texture, weight, or even scent of the parchment, making the discovery even more tangible.\nRefinerAgent > Elias polished the great lens, the beam cutting through the fog. A glint caught his eye ‚Äì a rolled parchment tucked into a crevice. Unfurling it, he felt a strange coolness emanate from the material, like hardened moonlight. Strange symbols pulsed with an internal, sapphire glow, charting an ocean no sailor knew. Awe warred with trepidation; the map felt ancient, humming with a forgotten magic. He traced a shimmering line, a sense of destiny dawning within him.\nCriticAgent > APPROVED\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"}],"execution_count":53},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n## Section 6: Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)\n\n### üéØ Next Steps\n\nReady for the next challenge? Stay tuned for Day 2 notebooks where we'll learn how to create **Custom Functions, use MCP Tools** and manage **Long-Running operations!**","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Kristopher Overholt](https://www.linkedin.com/in/koverholt) |","metadata":{}}]}